{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Apr  2 18:56:41 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:1A:00.0 Off |                  N/A |\n",
      "| 29%   32C    P8              17W / 250W |      1MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Wed_Nov_22_10:17:15_PST_2023\n",
      "Cuda compilation tools, release 12.3, V12.3.107\n",
      "Build cuda_12.3.r12.3/compiler.33567101_0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "!nvidia-smi\n",
    "!nvcc --version\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch-scatter in /net/galaxy/home/koes/vratins/miniforge3/envs/graph/lib/python3.10/site-packages (2.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import dgl.function as fn\n",
    "import torch\n",
    "from torch import nn, einsum\n",
    "import torch.nn as nn\n",
    "from torch_scatter import scatter_mean\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from typing import List, Tuple, Union, Dict\n",
    "\n",
    "import sys\n",
    "sys.path.append('/net/galaxy/home/koes/vratins/graphpocket/gnn')\n",
    "\n",
    "from dataloader import get_dataloader, create_dataset\n",
    "from graphpocket import GraphPocket\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prody\n",
    "\n",
    "prody.confProDy(verbosity='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gvp\n",
    "\n",
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "def _norm_no_nan(x, axis=-1, keepdims=False, eps=1e-8, sqrt=True):\n",
    "    '''\n",
    "    L2 norm of tensor clamped above a minimum value `eps`.\n",
    "    \n",
    "    :param sqrt: if `False`, returns the square of the L2 norm\n",
    "    '''\n",
    "    out = torch.clamp(torch.sum(torch.square(x), axis, keepdims), min=eps)\n",
    "    return torch.sqrt(out) if sqrt else out\n",
    "\n",
    "def _rbf(D, D_min=0., D_max=20., D_count=16):\n",
    "    '''\n",
    "    From https://github.com/jingraham/neurips19-graph-protein-design\n",
    "    \n",
    "    Returns an RBF embedding of `torch.Tensor` `D` along a new axis=-1.\n",
    "    That is, if `D` has shape [...dims], then the returned tensor will have\n",
    "    shape [...dims, D_count].\n",
    "    '''\n",
    "    device = D.device\n",
    "    D_mu = torch.linspace(D_min, D_max, D_count, device=device)\n",
    "    D_mu = D_mu.view([1, -1])\n",
    "    D_sigma = (D_max - D_min) / D_count\n",
    "    D_expand = torch.unsqueeze(D, -1)\n",
    "\n",
    "    RBF = torch.exp(-((D_expand - D_mu) / D_sigma) ** 2)\n",
    "    return RBF\n",
    "\n",
    "class GVP(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim_vectors_in,\n",
    "        dim_vectors_out,\n",
    "        dim_feats_in,\n",
    "        dim_feats_out,\n",
    "        hidden_vectors = None,\n",
    "        feats_activation = nn.SiLU(),\n",
    "        vectors_activation = nn.Sigmoid(),\n",
    "        vector_gating = True,\n",
    "        xavier_init = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dim_vectors_in = dim_vectors_in\n",
    "        self.dim_feats_in = dim_feats_in\n",
    "\n",
    "        self.dim_vectors_out = dim_vectors_out\n",
    "        dim_h = max(dim_vectors_in, dim_vectors_out) if hidden_vectors is None else hidden_vectors\n",
    "\n",
    "        # create Wh and Wu matricies\n",
    "        wh_k = 1/math.sqrt(dim_vectors_in)\n",
    "        wu_k = 1/math.sqrt(dim_h)\n",
    "        self.Wh = torch.zeros(dim_vectors_in, dim_h, dtype=torch.float32).uniform_(-wh_k, wh_k)\n",
    "        self.Wu = torch.zeros(dim_h, dim_vectors_out, dtype=torch.float32).uniform_(-wu_k, wu_k)\n",
    "        self.Wh = nn.Parameter(self.Wh)\n",
    "        self.Wu = nn.Parameter(self.Wu)\n",
    "\n",
    "        self.vectors_activation = vectors_activation\n",
    "\n",
    "        self.to_feats_out = nn.Sequential(\n",
    "            nn.Linear(dim_h + dim_feats_in, dim_feats_out),\n",
    "            feats_activation\n",
    "        )\n",
    "\n",
    "        # branching logic to use old GVP, or GVP with vector gating\n",
    "        if vector_gating:\n",
    "            self.scalar_to_vector_gates = nn.Linear(dim_feats_out, dim_vectors_out)\n",
    "            if xavier_init:\n",
    "                nn.init.xavier_uniform_(self.scalar_to_vector_gates.weight, gain=1)\n",
    "                nn.init.constant_(self.scalar_to_vector_gates.bias, 0)\n",
    "        else:\n",
    "            self.scalar_to_vector_gates = None\n",
    "\n",
    "    def forward(self, data):\n",
    "        feats, vectors = data\n",
    "        b, n, _, v, c  = *feats.shape, *vectors.shape\n",
    "\n",
    "        assert c == 3 and v == self.dim_vectors_in, 'vectors have wrong dimensions'\n",
    "        assert n == self.dim_feats_in, 'scalar features have wrong dimensions'\n",
    "\n",
    "        Vh = einsum('b v c, v h -> b h c', vectors, self.Wh)\n",
    "        Vu = einsum('b h c, h u -> b u c', Vh, self.Wu)\n",
    "\n",
    "        sh = _norm_no_nan(Vh)\n",
    "\n",
    "        s = torch.cat((feats, sh), dim = 1)\n",
    "\n",
    "        feats_out = self.to_feats_out(s)\n",
    "\n",
    "        if exists(self.scalar_to_vector_gates):\n",
    "            gating = self.scalar_to_vector_gates(feats_out)\n",
    "            gating = gating.unsqueeze(dim = -1)\n",
    "        else:\n",
    "            gating = _norm_no_nan(Vu)\n",
    "\n",
    "        vectors_out = self.vectors_activation(gating) * Vu\n",
    "\n",
    "        # if torch.isnan(feats_out).any() or torch.isnan(vectors_out).any():\n",
    "        #     raise ValueError(\"NaNs in GVP forward pass\")\n",
    "\n",
    "        return (feats_out, vectors_out)\n",
    "    \n",
    "class _VDropout(nn.Module):\n",
    "    '''\n",
    "    Vector channel dropout where the elements of each\n",
    "    vector channel are dropped together.\n",
    "    '''\n",
    "    def __init__(self, drop_rate):\n",
    "        super(_VDropout, self).__init__()\n",
    "        self.drop_rate = drop_rate\n",
    "        self.dummy_param = nn.Parameter(torch.empty(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        :param x: `torch.Tensor` corresponding to vector channels\n",
    "        '''\n",
    "        device = self.dummy_param.device\n",
    "        if not self.training:\n",
    "            return x\n",
    "        mask = torch.bernoulli(\n",
    "            (1 - self.drop_rate) * torch.ones(x.shape[:-1], device=device)\n",
    "        ).unsqueeze(-1)\n",
    "        x = mask * x / (1 - self.drop_rate)\n",
    "        return x\n",
    "    \n",
    "class GVPDropout(nn.Module):\n",
    "    \"\"\" Separate dropout for scalars and vectors. \"\"\"\n",
    "    def __init__(self, rate):\n",
    "        super().__init__()\n",
    "        self.vector_dropout = _VDropout(rate)\n",
    "        self.feat_dropout = nn.Dropout(rate)\n",
    "\n",
    "    def forward(self, feats, vectors):\n",
    "        return self.feat_dropout(feats), self.vector_dropout(vectors)\n",
    "\n",
    "\n",
    "class GVPLayerNorm(nn.Module):\n",
    "    \"\"\" Normal layer norm for scalars, nontrainable norm for vectors. \"\"\"\n",
    "    def __init__(self, feats_h_size, eps = 1e-5):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.feat_norm = nn.LayerNorm(feats_h_size)\n",
    "\n",
    "    def forward(self, feats, vectors):\n",
    "\n",
    "        normed_feats = self.feat_norm(feats)\n",
    "\n",
    "        vn = _norm_no_nan(vectors, axis=-1, keepdims=True, sqrt=False)\n",
    "        vn = torch.sqrt(torch.mean(vn, dim=-2, keepdim=True) + self.eps ) + self.eps\n",
    "        normed_vectors = vectors / vn\n",
    "        return normed_feats, normed_vectors\n",
    "    \n",
    "#convolution\n",
    "class GVPEdgeConv(nn.Module):\n",
    "\n",
    "    def __init__(self, scalar_size: int = 128, vector_size: int = 16,\n",
    "                  scalar_activation=nn.SiLU, vector_activation=nn.Sigmoid,\n",
    "                  n_message_gvps: int = 1, n_update_gvps: int = 1,\n",
    "                  rbf_dmax: float = 3.5, rbf_dim: int = 16,\n",
    "                  edge_feat_size: int = 0, message_norm: Union[float, str] = 4, dropout: float = 0.0,):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.scalar_size = scalar_size\n",
    "        self.vector_size = vector_size\n",
    "        self.scalar_activation = scalar_activation\n",
    "        self.vector_activation = vector_activation\n",
    "        self.n_message_gvps = n_message_gvps\n",
    "        self.n_update_gvps = n_update_gvps\n",
    "        self.edge_feat_size = edge_feat_size\n",
    "        self.rbf_dmax = rbf_dmax\n",
    "        self.rbf_dim = rbf_dim\n",
    "        self.dropout_rate = dropout\n",
    "        self.message_norm = message_norm\n",
    "\n",
    "        # create message passing function\n",
    "        message_gvps = []\n",
    "        for i in range(n_message_gvps):\n",
    "\n",
    "            dim_vectors_in = vector_size\n",
    "            dim_feats_in = scalar_size\n",
    "\n",
    "            # on the first layer, there is an extra edge vector for the displacement vector between the two node positions\n",
    "            if i == 0:\n",
    "                dim_vectors_in += 1\n",
    "                dim_feats_in += rbf_dim\n",
    "\n",
    "            message_gvps.append(\n",
    "                GVP(dim_vectors_in=dim_vectors_in, \n",
    "                    dim_vectors_out=vector_size, \n",
    "                    dim_feats_in=dim_feats_in, \n",
    "                    dim_feats_out=scalar_size, \n",
    "                    feats_activation=scalar_activation(), \n",
    "                    vectors_activation=vector_activation(), \n",
    "                    vector_gating=True)\n",
    "            )\n",
    "        self.edge_message = nn.Sequential(*message_gvps)\n",
    "\n",
    "        # create update function\n",
    "        update_gvps = []\n",
    "        for i in range(n_update_gvps):\n",
    "            update_gvps.append(\n",
    "                GVP(dim_vectors_in=vector_size, \n",
    "                    dim_vectors_out=vector_size, \n",
    "                    dim_feats_in=scalar_size, \n",
    "                    dim_feats_out=scalar_size, \n",
    "                    feats_activation=scalar_activation(), \n",
    "                    vectors_activation=vector_activation(), \n",
    "                    vector_gating=True)\n",
    "            )\n",
    "        self.node_update = nn.Sequential(*update_gvps)\n",
    "\n",
    "        \n",
    "        self.dropout = GVPDropout(self.dropout_rate)\n",
    "        self.message_layer_norm = GVPLayerNorm(self.scalar_size)\n",
    "        self.update_layer_norm = GVPLayerNorm(self.scalar_size)\n",
    "\n",
    "        if self.message_norm == 'mean':\n",
    "            self.agg_func = fn.mean\n",
    "        else:\n",
    "            self.agg_func = fn.sum\n",
    "\n",
    "    def forward(self, g: dgl.DGLHeteroGraph, \n",
    "                rec_feats: Tuple[torch.Tensor, torch.Tensor, torch.Tensor], \n",
    "                edge_feats: torch.Tensor = None, \n",
    "                z: Union[float, torch.Tensor] = 1):\n",
    "        # vec_feat has shape (n_nodes, n_vectors, 3)\n",
    "\n",
    "        with g.local_scope():\n",
    "\n",
    "            scalar_feat, coord_feat, vec_feat = rec_feats\n",
    "            g.ndata[\"h\"] = scalar_feat\n",
    "            g.ndata[\"x\"] = coord_feat\n",
    "            g.ndata[\"v\"] = vec_feat\n",
    "            \n",
    "            # edge feature\n",
    "            if self.edge_feat_size > 0:\n",
    "                assert edge_feats is not None, \"Edge features must be provided.\"\n",
    "                g.edata[\"a\"] = edge_feats\n",
    "\n",
    "            # get vectors between node positions\n",
    "            g.apply_edges(fn.u_sub_v(\"x\", \"x\", \"x_diff\"))\n",
    "\n",
    "            # normalize x_diff and compute rbf embedding of edge distance\n",
    "            # dij = torch.norm(g.edges[self.edge_type].data['x_diff'], dim=-1, keepdim=True)\n",
    "            dij = _norm_no_nan(g.edata['x_diff'], keepdims=True) + 1e-8\n",
    "            g.edata['x_diff'] = g.edata['x_diff'] / dij\n",
    "            g.edata['d'] = _rbf(dij.squeeze(1), D_max=self.rbf_dmax, D_count=self.rbf_dim)\n",
    "\n",
    "            # compute messages on every edge\n",
    "            g.apply_edges(self.message)\n",
    "\n",
    "            # aggregate messages from every edge\n",
    "            g.update_all(fn.copy_e(\"scalar_msg\", \"m\"), self.agg_func(\"m\", \"scalar_msg\"))\n",
    "            g.update_all(fn.copy_e(\"vec_msg\", \"m\"), self.agg_func(\"m\", \"vec_msg\"))\n",
    "\n",
    "\n",
    "            # get aggregated scalar and vector messages\n",
    "            scalar_msg = g.ndata[\"scalar_msg\"] / z\n",
    "            if isinstance(z, torch.Tensor):\n",
    "                z = z.unsqueeze(-1)\n",
    "            vec_msg = g.ndata[\"vec_msg\"] / z\n",
    "\n",
    "            # dropout scalar and vector messages\n",
    "            scalar_msg, vec_msg = self.dropout(scalar_msg, vec_msg)\n",
    "\n",
    "            # update scalar and vector features, apply layernorm\n",
    "            scalar_feat = g.ndata['h'] + scalar_msg\n",
    "            vec_feat = g.ndata['v'] + vec_msg\n",
    "            scalar_feat, vec_feat = self.message_layer_norm(scalar_feat, vec_feat)\n",
    "\n",
    "            # apply node update function, apply dropout to residuals, apply layernorm\n",
    "            scalar_residual, vec_residual = self.node_update((scalar_feat, vec_feat))\n",
    "            scalar_residual, vec_residual = self.dropout(scalar_residual, vec_residual)\n",
    "            scalar_feat = scalar_feat + scalar_residual\n",
    "            vec_feat = vec_feat + vec_residual\n",
    "            scalar_feat, vec_feat = self.update_layer_norm(scalar_feat, vec_feat)\n",
    "\n",
    "        return scalar_feat, vec_feat\n",
    "\n",
    "    def message(self, edges):\n",
    "\n",
    "        vec_feats = torch.cat([edges.data[\"x_diff\"].unsqueeze(1), edges.src[\"v\"]], dim=1)\n",
    "\n",
    "        # create scalar features\n",
    "        scalar_feats = [ edges.src['h'], edges.data['d'] ]\n",
    "\n",
    "        # if self.edge_feat_size > 0:\n",
    "        #     scalar_feats.append(edges.data['a'])\n",
    "\n",
    "        scalar_feats = torch.cat(scalar_feats, dim=1)\n",
    "\n",
    "        scalar_message, vector_message = self.edge_message((scalar_feats, vec_feats))\n",
    "\n",
    "        return {\"scalar_msg\": scalar_message, \"vec_msg\": vector_message}\n",
    "\n",
    "    \n",
    "class ReceptorEncoderGVP(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 in_scalar_size: int, \n",
    "                 out_scalar_size: int = 128, \n",
    "                 n_message_gvps: int = 1,\n",
    "                 n_update_gvps: int = 1,\n",
    "                 vector_size: int = 16,\n",
    "                 n_convs: int = 3, \n",
    "                 message_norm: Union[float, str] = 10, \n",
    "                 dropout: float = 0.0,\n",
    "                 rbf_dmax: float = 3.5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_convs = n_convs\n",
    "        self.in_scalar_size = in_scalar_size\n",
    "        self.out_scalar_size = out_scalar_size\n",
    "        self.vector_size = vector_size\n",
    "        self.dropout_rate = dropout\n",
    "        self.message_norm = message_norm\n",
    "        self.rbf_dmax = rbf_dmax\n",
    "\n",
    "        # check the message norm argument\n",
    "        if isinstance(message_norm, str) and message_norm != 'mean':\n",
    "            raise ValueError(f'message norm must be either a float, int, or \"mean\". Got {message_norm}')\n",
    "        elif isinstance(message_norm, float) or isinstance(message_norm, int):\n",
    "            pass\n",
    "        elif not isinstance(message_norm, (str, float, int)):\n",
    "            raise ValueError(f'message norm must be either a float, int, or \"mean\". Got {message_norm}')\n",
    "\n",
    "        # create functions to embed scalar features to the desired size\n",
    "        self.scalar_embed = nn.Sequential(\n",
    "            nn.Linear(in_scalar_size, out_scalar_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(out_scalar_size, out_scalar_size),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "        self.scalar_norm = nn.LayerNorm(out_scalar_size)\n",
    "\n",
    "        edge_feat_size = 1\n",
    "\n",
    "        # create rec-rec convolutional layers\n",
    "        self.rec_conv_layers = nn.ModuleList()\n",
    "        for _ in range(n_convs):\n",
    "            self.rec_conv_layers.append(GVPEdgeConv(\n",
    "                scalar_size=out_scalar_size,\n",
    "                vector_size=vector_size,\n",
    "                n_message_gvps=n_message_gvps,\n",
    "                n_update_gvps=n_update_gvps,\n",
    "                edge_feat_size=edge_feat_size,\n",
    "                dropout=dropout,\n",
    "                message_norm=message_norm,\n",
    "                rbf_dmax=rbf_dmax\n",
    "            ))\n",
    "\n",
    "    def forward(self, g: dgl.DGLHeteroGraph, batch_idx: torch.Tensor):\n",
    "\n",
    "        device = g.device\n",
    "        batch_size = g.batch_size\n",
    "\n",
    "        # get scalar features\n",
    "        rec_scalar_feat = g.ndata[\"h_0\"]\n",
    "\n",
    "        # embed scalar features\n",
    "        rec_scalar_feat = self.scalar_embed(rec_scalar_feat)\n",
    "        rec_scalar_feat = self.scalar_norm(rec_scalar_feat)\n",
    "\n",
    "        # initialize receptor vector features\n",
    "        rec_vec_feat = torch.zeros((g.num_nodes(), self.vector_size, 3), device=device)\n",
    "\n",
    "        # get edge features\n",
    "        edge_feat = g.edata['a']\n",
    "\n",
    "        # get coordinate features\n",
    "        rec_coord_feat = g.ndata['x_0']\n",
    "\n",
    "        # compute the normalization factor for the messages if necessary\n",
    "        if self.message_norm == 'mean':\n",
    "            # set z to 1. the receptor convolutional layer will use mean aggregation instead of sum\n",
    "            z = 1\n",
    "        elif self.message_norm == 0:\n",
    "            # if messsage_norm is 0, we normalize by the average in-degree of the graph\n",
    "            z = g.batch_num_edges() / g.batch_num_nodes()\n",
    "            z = z[batch_idx].view(-1, 1)\n",
    "        else:\n",
    "            z = self.message_norm\n",
    "\n",
    "        # apply receptor-receptor convolutions\n",
    "        for i in range(self.n_convs):\n",
    "            rec_feats = (rec_scalar_feat, rec_coord_feat, rec_vec_feat)\n",
    "            rec_scalar_feat, rec_vec_feat = self.rec_conv_layers[i](g, rec_feats=rec_feats, edge_feats=edge_feat, z=z)\n",
    "\n",
    "        vector_features_flattened = rec_vec_feat.view(rec_vec_feat.size(0), -1)  # Reshapes to [num_nodes, num_vectors * vector_dim]\n",
    "\n",
    "        #concatenate the scalar and vector features\n",
    "        flattened_features = torch.cat([rec_scalar_feat, vector_features_flattened], dim=1)\n",
    "        #average the features across the graphs in batch, return a tensor of shape [batch_size, feature length]\n",
    "        graph_features = scatter_mean(flattened_features, batch_idx, dim=0)\n",
    "        \n",
    "        return graph_features\n",
    "\n",
    "\n",
    "def con_loss(output1, output2, labels, margin=1.0):\n",
    "\n",
    "    dists = F.pairwise_distance(output1, output2).view(-1)\n",
    "    \n",
    "    pos_loss = dists.pow(2)\n",
    "    neg_loss = torch.clamp(margin - dists, min=0).pow(2)\n",
    "\n",
    "    loss_contrastive = torch.sum(pos_loss * labels + neg_loss * (1 - labels)) / labels.numel()\n",
    "\n",
    "    return loss_contrastive, dists[labels > 0.5].detach(), dists[labels < 0.5].detach()\n",
    "\n",
    "def get_batch_idx(g: dgl.DGLHeteroGraph) -> torch.Tensor:\n",
    "        \n",
    "    batch_size = g.batch_size\n",
    "    device = g.device\n",
    "    num_nodes_per_graph = g.batch_num_nodes()\n",
    "\n",
    "    batch_indxs = torch.cat([\n",
    "        torch.full((num_nodes,), i, dtype=torch.long, device=device)\n",
    "        for i, num_nodes in enumerate(num_nodes_per_graph)\n",
    "    ])\n",
    "    \n",
    "    return batch_indxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([357], device='cuda:0')\n",
      "Graph(num_nodes=357, num_edges=1071,\n",
      "      ndata_schemes={'x_0': Scheme(shape=(3,), dtype=torch.float32), 'h_0': Scheme(shape=(4,), dtype=torch.float32)}\n",
      "      edata_schemes={'a': Scheme(shape=(1,), dtype=torch.float32)})\n",
      "Updated Features Shape: torch.Size([1, 176])\n"
     ]
    }
   ],
   "source": [
    "#setup\n",
    "\n",
    "pocket_to_graph = GraphPocket()\n",
    "\n",
    "g = pocket_to_graph(pocket_path='../../dataset_graph/data/11asA/11asA_pocket.pdb')\n",
    "g = g.to(device)\n",
    "\n",
    "for ntype in g.ntypes:\n",
    "    print(g.batch_num_nodes(ntype))\n",
    "\n",
    "print(g)\n",
    "\n",
    "model = ReceptorEncoderGVP(\n",
    "    in_scalar_size=4,    #Matching the node_features dimension\n",
    "    out_scalar_size=128,  #Desired output scalar size\n",
    "    vector_size=16,       #Desired vector size\n",
    "    n_convs=3,            #Number of convolution layers\n",
    "    dropout=0.1           #Dropout rate\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "batch = torch.tensor([0]).to(device)\n",
    "\n",
    "updated_g = model(g, batch)\n",
    "\n",
    "print(\"Updated Features Shape:\", updated_g.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting dataset based on Sequence Clusters..\n",
      "Split complete, reading pockets..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering train pos_list: 100%|██████████| 505116/505116 [00:44<00:00, 11467.76it/s]\n",
      "Filtering train neg_list: 100%|██████████| 556810/556810 [00:47<00:00, 11745.80it/s]\n",
      "Reading train Pockets: 5955it [00:50, 117.80it/s]\n",
      "Creating train Positive Pocket Pairs: 100%|██████████| 326259/326259 [00:00<00:00, 1434647.00it/s]\n",
      "Creating train Negative Pocket Pairs: 100%|██████████| 378576/378576 [00:01<00:00, 312604.78it/s] \n",
      "Filtering test pos_list: 100%|██████████| 505116/505116 [00:11<00:00, 45260.23it/s]\n",
      "Filtering test neg_list: 100%|██████████| 556810/556810 [00:12<00:00, 45531.96it/s]\n",
      "Reading test Pockets: 1543it [00:13, 112.07it/s]\n",
      "Creating test Positive Pocket Pairs: 100%|██████████| 21254/21254 [00:00<00:00, 1149348.10it/s]\n",
      "Creating test Negative Pocket Pairs: 100%|██████████| 16099/16099 [00:00<00:00, 1161884.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.059365952014923\n"
     ]
    }
   ],
   "source": [
    "#dataloader\n",
    "import time\n",
    "\n",
    "start= time.time()\n",
    "\n",
    "pos_path, neg_path = '../../dataset_graph/TOUGH-M1/TOUGH-M1_positive.list', '../../dataset_graph/TOUGH-M1/TOUGH-M1_negative.list'\n",
    "pocket_path = '../../dataset_graph/data'\n",
    "seq_file = '../cluster_map.pkl'\n",
    "\n",
    "train_dataset, test_dataset = create_dataset(pos_path, neg_path, pocket_path, seq_file, fold_nr=0, type='seq')\n",
    "train_dataloader = get_dataloader(train_dataset, batch_size=32, num_workers=4)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print((end-start)/60.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 22027/22027 [35:26<00:00, 10.36it/s, Loss=0.161, neg_dist=tensor(1.2553, device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "\n",
    "epochs = 1\n",
    "warmup_epochs = 5\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)\n",
    "epoch_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    progress_bar = tqdm(enumerate(train_dataloader), total=len(train_dataloader), desc=f'Epoch {epoch+1}/{epochs}')\n",
    "    \n",
    "    for batch_idx, ((graph1, graph2), label) in progress_bar:\n",
    "        graph1, graph2, label = graph1.to(device), graph2.to(device), label.to(device)\n",
    "\n",
    "        batch_indx1 = get_batch_idx(graph1).to(device)\n",
    "        batch_indx2 = get_batch_idx(graph2).to(device)\n",
    "        \n",
    "        output1 = model(graph1, batch_indx1)\n",
    "        output2 = model(graph2, batch_indx2)\n",
    "\n",
    "        # print(output1.shape)\n",
    "        # print(output2.shape)\n",
    "        \n",
    "        loss, pos_dist, neg_dist = con_loss(output1, output2, label)\n",
    "\n",
    "        # print(\"loss: \", loss)\n",
    "        # print(\"pos_dist: \", pos_dist, \"len pos: \", len(pos_dist))\n",
    "        # print(\"neg_dist: \", neg_dist, \"len neg: \", len(neg_dist))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print(loss.item())\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        progress_bar.set_postfix({'Loss': running_loss/(batch_idx+1), 'neg_dist': torch.mean(neg_dist)})\n",
    "        epoch_losses.append(running_loss/(batch_idx+1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(epoch_losses, marker='o')  # 'o' adds markers to each data point\n",
    "plt.title('Line Plot of List Items')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
