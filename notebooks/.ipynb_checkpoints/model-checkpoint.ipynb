{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr  3 13:17:04 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.29.06              Driver Version: 545.29.06    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA RTX A4500               Off | 00000000:1A:00.0 Off |                  Off |\n",
      "| 30%   47C    P8              15W / 200W |      2MiB / 20470MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA RTX A4500               Off | 00000000:3D:00.0 Off |                  Off |\n",
      "| 30%   31C    P8              16W / 200W |      2MiB / 20470MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Wed_Nov_22_10:17:15_PST_2023\n",
      "Cuda compilation tools, release 12.3, V12.3.107\n",
      "Build cuda_12.3.r12.3/compiler.33567101_0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "!nvidia-smi\n",
    "!nvcc --version\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch-scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import dgl.function as fn\n",
    "import torch\n",
    "from torch import nn, einsum\n",
    "import torch.nn as nn\n",
    "from torch_scatter import scatter_mean\n",
    "import math\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from typing import List, Tuple, Union, Dict\n",
    "\n",
    "import sys\n",
    "sys.path.append('/net/galaxy/home/koes/vratins/graphpocket/gnn')\n",
    "\n",
    "from dataloader import get_dataloader, create_dataset\n",
    "from graphpocket import GraphPocket\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prody\n",
    "\n",
    "prody.confProDy(verbosity='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gvp\n",
    "\n",
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "def _norm_no_nan(x, axis=-1, keepdims=False, eps=1e-8, sqrt=True):\n",
    "    '''\n",
    "    L2 norm of tensor clamped above a minimum value `eps`.\n",
    "    \n",
    "    :param sqrt: if `False`, returns the square of the L2 norm\n",
    "    '''\n",
    "    out = torch.clamp(torch.sum(torch.square(x), axis, keepdims), min=eps)\n",
    "    return torch.sqrt(out) if sqrt else out\n",
    "\n",
    "def _rbf(D, D_min=0., D_max=20., D_count=16):\n",
    "    '''\n",
    "    From https://github.com/jingraham/neurips19-graph-protein-design\n",
    "    \n",
    "    Returns an RBF embedding of `torch.Tensor` `D` along a new axis=-1.\n",
    "    That is, if `D` has shape [...dims], then the returned tensor will have\n",
    "    shape [...dims, D_count].\n",
    "    '''\n",
    "    device = D.device\n",
    "    D_mu = torch.linspace(D_min, D_max, D_count, device=device)\n",
    "    D_mu = D_mu.view([1, -1])\n",
    "    D_sigma = (D_max - D_min) / D_count\n",
    "    D_expand = torch.unsqueeze(D, -1)\n",
    "\n",
    "    RBF = torch.exp(-((D_expand - D_mu) / D_sigma) ** 2)\n",
    "    return RBF\n",
    "\n",
    "class GVP(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim_vectors_in,\n",
    "        dim_vectors_out,\n",
    "        dim_feats_in,\n",
    "        dim_feats_out,\n",
    "        hidden_vectors = None,\n",
    "        feats_activation = nn.SiLU(),\n",
    "        vectors_activation = nn.Sigmoid(),\n",
    "        vector_gating = True,\n",
    "        xavier_init = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dim_vectors_in = dim_vectors_in\n",
    "        self.dim_feats_in = dim_feats_in\n",
    "\n",
    "        self.dim_vectors_out = dim_vectors_out\n",
    "        dim_h = max(dim_vectors_in, dim_vectors_out) if hidden_vectors is None else hidden_vectors\n",
    "\n",
    "        # create Wh and Wu matricies\n",
    "        wh_k = 1/math.sqrt(dim_vectors_in)\n",
    "        wu_k = 1/math.sqrt(dim_h)\n",
    "        self.Wh = torch.zeros(dim_vectors_in, dim_h, dtype=torch.float32).uniform_(-wh_k, wh_k)\n",
    "        self.Wu = torch.zeros(dim_h, dim_vectors_out, dtype=torch.float32).uniform_(-wu_k, wu_k)\n",
    "        self.Wh = nn.Parameter(self.Wh)\n",
    "        self.Wu = nn.Parameter(self.Wu)\n",
    "\n",
    "        self.vectors_activation = vectors_activation\n",
    "\n",
    "        self.to_feats_out = nn.Sequential(\n",
    "            nn.Linear(dim_h + dim_feats_in, dim_feats_out),\n",
    "            feats_activation\n",
    "        )\n",
    "\n",
    "        # branching logic to use old GVP, or GVP with vector gating\n",
    "        if vector_gating:\n",
    "            self.scalar_to_vector_gates = nn.Linear(dim_feats_out, dim_vectors_out)\n",
    "            if xavier_init:\n",
    "                nn.init.xavier_uniform_(self.scalar_to_vector_gates.weight, gain=1)\n",
    "                nn.init.constant_(self.scalar_to_vector_gates.bias, 0)\n",
    "        else:\n",
    "            self.scalar_to_vector_gates = None\n",
    "\n",
    "    def forward(self, data):\n",
    "        feats, vectors = data\n",
    "        b, n, _, v, c  = *feats.shape, *vectors.shape\n",
    "\n",
    "        assert c == 3 and v == self.dim_vectors_in, 'vectors have wrong dimensions'\n",
    "        assert n == self.dim_feats_in, 'scalar features have wrong dimensions'\n",
    "\n",
    "        Vh = einsum('b v c, v h -> b h c', vectors, self.Wh)\n",
    "        Vu = einsum('b h c, h u -> b u c', Vh, self.Wu)\n",
    "\n",
    "        sh = _norm_no_nan(Vh)\n",
    "\n",
    "        s = torch.cat((feats, sh), dim = 1)\n",
    "\n",
    "        feats_out = self.to_feats_out(s)\n",
    "\n",
    "        if exists(self.scalar_to_vector_gates):\n",
    "            gating = self.scalar_to_vector_gates(feats_out)\n",
    "            gating = gating.unsqueeze(dim = -1)\n",
    "        else:\n",
    "            gating = _norm_no_nan(Vu)\n",
    "\n",
    "        vectors_out = self.vectors_activation(gating) * Vu\n",
    "\n",
    "        # if torch.isnan(feats_out).any() or torch.isnan(vectors_out).any():\n",
    "        #     raise ValueError(\"NaNs in GVP forward pass\")\n",
    "\n",
    "        return (feats_out, vectors_out)\n",
    "    \n",
    "class _VDropout(nn.Module):\n",
    "    '''\n",
    "    Vector channel dropout where the elements of each\n",
    "    vector channel are dropped together.\n",
    "    '''\n",
    "    def __init__(self, drop_rate):\n",
    "        super(_VDropout, self).__init__()\n",
    "        self.drop_rate = drop_rate\n",
    "        self.dummy_param = nn.Parameter(torch.empty(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        :param x: `torch.Tensor` corresponding to vector channels\n",
    "        '''\n",
    "        device = self.dummy_param.device\n",
    "        if not self.training:\n",
    "            return x\n",
    "        mask = torch.bernoulli(\n",
    "            (1 - self.drop_rate) * torch.ones(x.shape[:-1], device=device)\n",
    "        ).unsqueeze(-1)\n",
    "        x = mask * x / (1 - self.drop_rate)\n",
    "        return x\n",
    "    \n",
    "class GVPDropout(nn.Module):\n",
    "    \"\"\" Separate dropout for scalars and vectors. \"\"\"\n",
    "    def __init__(self, rate):\n",
    "        super().__init__()\n",
    "        self.vector_dropout = _VDropout(rate)\n",
    "        self.feat_dropout = nn.Dropout(rate)\n",
    "\n",
    "    def forward(self, feats, vectors):\n",
    "        return self.feat_dropout(feats), self.vector_dropout(vectors)\n",
    "\n",
    "\n",
    "class GVPLayerNorm(nn.Module):\n",
    "    \"\"\" Normal layer norm for scalars, nontrainable norm for vectors. \"\"\"\n",
    "    def __init__(self, feats_h_size, eps = 1e-5):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.feat_norm = nn.LayerNorm(feats_h_size)\n",
    "\n",
    "    def forward(self, feats, vectors):\n",
    "\n",
    "        normed_feats = self.feat_norm(feats)\n",
    "\n",
    "        vn = _norm_no_nan(vectors, axis=-1, keepdims=True, sqrt=False)\n",
    "        vn = torch.sqrt(torch.mean(vn, dim=-2, keepdim=True) + self.eps ) + self.eps\n",
    "        normed_vectors = vectors / vn\n",
    "        return normed_feats, normed_vectors\n",
    "    \n",
    "#convolution\n",
    "class GVPEdgeConv(nn.Module):\n",
    "\n",
    "    def __init__(self, scalar_size: int = 128, vector_size: int = 16,\n",
    "                  scalar_activation=nn.SiLU, vector_activation=nn.Sigmoid,\n",
    "                  n_message_gvps: int = 1, n_update_gvps: int = 1,\n",
    "                  rbf_dmax: float = 3.5, rbf_dim: int = 16,\n",
    "                  edge_feat_size: int = 0, message_norm: Union[float, str] = 4, dropout: float = 0.0,):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.scalar_size = scalar_size\n",
    "        self.vector_size = vector_size\n",
    "        self.scalar_activation = scalar_activation\n",
    "        self.vector_activation = vector_activation\n",
    "        self.n_message_gvps = n_message_gvps\n",
    "        self.n_update_gvps = n_update_gvps\n",
    "        self.edge_feat_size = edge_feat_size\n",
    "        self.rbf_dmax = rbf_dmax\n",
    "        self.rbf_dim = rbf_dim\n",
    "        self.dropout_rate = dropout\n",
    "        self.message_norm = message_norm\n",
    "\n",
    "        # create message passing function\n",
    "        message_gvps = []\n",
    "        for i in range(n_message_gvps):\n",
    "\n",
    "            dim_vectors_in = vector_size\n",
    "            dim_feats_in = scalar_size\n",
    "\n",
    "            # on the first layer, there is an extra edge vector for the displacement vector between the two node positions\n",
    "            if i == 0:\n",
    "                dim_vectors_in += 1\n",
    "                dim_feats_in += rbf_dim\n",
    "\n",
    "            message_gvps.append(\n",
    "                GVP(dim_vectors_in=dim_vectors_in, \n",
    "                    dim_vectors_out=vector_size, \n",
    "                    dim_feats_in=dim_feats_in, \n",
    "                    dim_feats_out=scalar_size, \n",
    "                    feats_activation=scalar_activation(), \n",
    "                    vectors_activation=vector_activation(), \n",
    "                    vector_gating=True)\n",
    "            )\n",
    "        self.edge_message = nn.Sequential(*message_gvps)\n",
    "\n",
    "        # create update function\n",
    "        update_gvps = []\n",
    "        for i in range(n_update_gvps):\n",
    "            update_gvps.append(\n",
    "                GVP(dim_vectors_in=vector_size, \n",
    "                    dim_vectors_out=vector_size, \n",
    "                    dim_feats_in=scalar_size, \n",
    "                    dim_feats_out=scalar_size, \n",
    "                    feats_activation=scalar_activation(), \n",
    "                    vectors_activation=vector_activation(), \n",
    "                    vector_gating=True)\n",
    "            )\n",
    "        self.node_update = nn.Sequential(*update_gvps)\n",
    "\n",
    "        \n",
    "        self.dropout = GVPDropout(self.dropout_rate)\n",
    "        self.message_layer_norm = GVPLayerNorm(self.scalar_size)\n",
    "        self.update_layer_norm = GVPLayerNorm(self.scalar_size)\n",
    "\n",
    "        if self.message_norm == 'mean':\n",
    "            self.agg_func = fn.mean\n",
    "        else:\n",
    "            self.agg_func = fn.sum\n",
    "\n",
    "    def forward(self, g: dgl.DGLHeteroGraph, \n",
    "                rec_feats: Tuple[torch.Tensor, torch.Tensor, torch.Tensor], \n",
    "                edge_feats: torch.Tensor = None, \n",
    "                z: Union[float, torch.Tensor] = 1):\n",
    "        # vec_feat has shape (n_nodes, n_vectors, 3)\n",
    "\n",
    "        with g.local_scope():\n",
    "\n",
    "            scalar_feat, coord_feat, vec_feat = rec_feats\n",
    "            g.ndata[\"h\"] = scalar_feat\n",
    "            g.ndata[\"x\"] = coord_feat\n",
    "            g.ndata[\"v\"] = vec_feat\n",
    "            \n",
    "            # edge feature\n",
    "            if self.edge_feat_size > 0:\n",
    "                assert edge_feats is not None, \"Edge features must be provided.\"\n",
    "                g.edata[\"a\"] = edge_feats\n",
    "\n",
    "            # get vectors between node positions\n",
    "            g.apply_edges(fn.u_sub_v(\"x\", \"x\", \"x_diff\"))\n",
    "\n",
    "            # normalize x_diff and compute rbf embedding of edge distance\n",
    "            # dij = torch.norm(g.edges[self.edge_type].data['x_diff'], dim=-1, keepdim=True)\n",
    "            dij = _norm_no_nan(g.edata['x_diff'], keepdims=True) + 1e-8\n",
    "            g.edata['x_diff'] = g.edata['x_diff'] / dij\n",
    "            g.edata['d'] = _rbf(dij.squeeze(1), D_max=self.rbf_dmax, D_count=self.rbf_dim)\n",
    "\n",
    "            # compute messages on every edge\n",
    "            g.apply_edges(self.message)\n",
    "\n",
    "            # aggregate messages from every edge\n",
    "            g.update_all(fn.copy_e(\"scalar_msg\", \"m\"), self.agg_func(\"m\", \"scalar_msg\"))\n",
    "            g.update_all(fn.copy_e(\"vec_msg\", \"m\"), self.agg_func(\"m\", \"vec_msg\"))\n",
    "\n",
    "\n",
    "            # get aggregated scalar and vector messages\n",
    "            scalar_msg = g.ndata[\"scalar_msg\"] / z\n",
    "            if isinstance(z, torch.Tensor):\n",
    "                z = z.unsqueeze(-1)\n",
    "            vec_msg = g.ndata[\"vec_msg\"] / z\n",
    "\n",
    "            # dropout scalar and vector messages\n",
    "            scalar_msg, vec_msg = self.dropout(scalar_msg, vec_msg)\n",
    "\n",
    "            # update scalar and vector features, apply layernorm\n",
    "            scalar_feat = g.ndata['h'] + scalar_msg\n",
    "            vec_feat = g.ndata['v'] + vec_msg\n",
    "            scalar_feat, vec_feat = self.message_layer_norm(scalar_feat, vec_feat)\n",
    "\n",
    "            # apply node update function, apply dropout to residuals, apply layernorm\n",
    "            scalar_residual, vec_residual = self.node_update((scalar_feat, vec_feat))\n",
    "            scalar_residual, vec_residual = self.dropout(scalar_residual, vec_residual)\n",
    "            scalar_feat = scalar_feat + scalar_residual\n",
    "            vec_feat = vec_feat + vec_residual\n",
    "            scalar_feat, vec_feat = self.update_layer_norm(scalar_feat, vec_feat)\n",
    "\n",
    "        return scalar_feat, vec_feat\n",
    "\n",
    "    def message(self, edges):\n",
    "\n",
    "        vec_feats = torch.cat([edges.data[\"x_diff\"].unsqueeze(1), edges.src[\"v\"]], dim=1)\n",
    "\n",
    "        # create scalar features\n",
    "        scalar_feats = [ edges.src['h'], edges.data['d'] ]\n",
    "\n",
    "        # if self.edge_feat_size > 0:\n",
    "        #     scalar_feats.append(edges.data['a'])\n",
    "\n",
    "        scalar_feats = torch.cat(scalar_feats, dim=1)\n",
    "\n",
    "        scalar_message, vector_message = self.edge_message((scalar_feats, vec_feats))\n",
    "\n",
    "        return {\"scalar_msg\": scalar_message, \"vec_msg\": vector_message}\n",
    "\n",
    "    \n",
    "class ReceptorEncoderGVP(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 in_scalar_size: int, \n",
    "                 out_scalar_size: int = 128, \n",
    "                 n_message_gvps: int = 1,\n",
    "                 n_update_gvps: int = 1,\n",
    "                 vector_size: int = 16,\n",
    "                 n_convs: int = 3, \n",
    "                 message_norm: Union[float, str] = 10, \n",
    "                 dropout: float = 0.0,\n",
    "                 rbf_dmax: float = 3.5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_convs = n_convs\n",
    "        self.in_scalar_size = in_scalar_size\n",
    "        self.out_scalar_size = out_scalar_size\n",
    "        self.vector_size = vector_size\n",
    "        self.dropout_rate = dropout\n",
    "        self.message_norm = message_norm\n",
    "        self.rbf_dmax = rbf_dmax\n",
    "\n",
    "        # check the message norm argument\n",
    "        if isinstance(message_norm, str) and message_norm != 'mean':\n",
    "            raise ValueError(f'message norm must be either a float, int, or \"mean\". Got {message_norm}')\n",
    "        elif isinstance(message_norm, float) or isinstance(message_norm, int):\n",
    "            pass\n",
    "        elif not isinstance(message_norm, (str, float, int)):\n",
    "            raise ValueError(f'message norm must be either a float, int, or \"mean\". Got {message_norm}')\n",
    "\n",
    "        # create functions to embed scalar features to the desired size\n",
    "        self.scalar_embed = nn.Sequential(\n",
    "            nn.Linear(in_scalar_size, out_scalar_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(out_scalar_size, out_scalar_size),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "        self.scalar_norm = nn.LayerNorm(out_scalar_size)\n",
    "\n",
    "        edge_feat_size = 1\n",
    "\n",
    "        # create rec-rec convolutional layers\n",
    "        self.rec_conv_layers = nn.ModuleList()\n",
    "        for _ in range(n_convs):\n",
    "            self.rec_conv_layers.append(GVPEdgeConv(\n",
    "                scalar_size=out_scalar_size,\n",
    "                vector_size=vector_size,\n",
    "                n_message_gvps=n_message_gvps,\n",
    "                n_update_gvps=n_update_gvps,\n",
    "                edge_feat_size=edge_feat_size,\n",
    "                dropout=dropout,\n",
    "                message_norm=message_norm,\n",
    "                rbf_dmax=rbf_dmax\n",
    "            ))\n",
    "\n",
    "    def forward(self, g: dgl.DGLHeteroGraph, batch_idx: torch.Tensor):\n",
    "\n",
    "        device = g.device\n",
    "        batch_size = g.batch_size\n",
    "\n",
    "        # get scalar features\n",
    "        rec_scalar_feat = g.ndata[\"h_0\"]\n",
    "\n",
    "        # embed scalar features\n",
    "        rec_scalar_feat = self.scalar_embed(rec_scalar_feat)\n",
    "        rec_scalar_feat = self.scalar_norm(rec_scalar_feat)\n",
    "\n",
    "        # initialize receptor vector features\n",
    "        rec_vec_feat = torch.zeros((g.num_nodes(), self.vector_size, 3), device=device)\n",
    "\n",
    "        # get edge features\n",
    "        edge_feat = g.edata['a']\n",
    "\n",
    "        # get coordinate features\n",
    "        rec_coord_feat = g.ndata['x_0']\n",
    "\n",
    "        # compute the normalization factor for the messages if necessary\n",
    "        if self.message_norm == 'mean':\n",
    "            # set z to 1. the receptor convolutional layer will use mean aggregation instead of sum\n",
    "            z = 1\n",
    "        elif self.message_norm == 0:\n",
    "            # if messsage_norm is 0, we normalize by the average in-degree of the graph\n",
    "            z = g.batch_num_edges() / g.batch_num_nodes()\n",
    "            z = z[batch_idx].view(-1, 1)\n",
    "        else:\n",
    "            z = self.message_norm\n",
    "\n",
    "        # apply receptor-receptor convolutions\n",
    "        for i in range(self.n_convs):\n",
    "            rec_feats = (rec_scalar_feat, rec_coord_feat, rec_vec_feat)\n",
    "            rec_scalar_feat, rec_vec_feat = self.rec_conv_layers[i](g, rec_feats=rec_feats, edge_feats=edge_feat, z=z)\n",
    "\n",
    "        vector_features_flattened = rec_vec_feat.view(rec_vec_feat.size(0), -1)  # Reshapes to [num_nodes, num_vectors * vector_dim]\n",
    "\n",
    "        #concatenate the scalar and vector features\n",
    "        flattened_features = torch.cat([rec_scalar_feat, vector_features_flattened], dim=1)\n",
    "        #average the features across the graphs in batch, return a tensor of shape [batch_size, feature length]\n",
    "        graph_features = scatter_mean(flattened_features, batch_idx, dim=0)\n",
    "        \n",
    "        return graph_features\n",
    "\n",
    "\n",
    "def con_loss(output1, output2, labels, margin=1.0):\n",
    "\n",
    "    dists = F.pairwise_distance(output1, output2).view(-1)\n",
    "    \n",
    "    pos_loss = dists.pow(2)\n",
    "    neg_loss = torch.clamp(margin - dists, min=0).pow(2)\n",
    "\n",
    "    loss_contrastive = torch.sum(pos_loss * labels + neg_loss * (1 - labels)) / labels.numel()\n",
    "\n",
    "    return loss_contrastive, dists[labels > 0.5].detach(), dists[labels < 0.5].detach()\n",
    "\n",
    "def get_batch_idx(g: dgl.DGLHeteroGraph) -> torch.Tensor:\n",
    "        \n",
    "    batch_size = g.batch_size\n",
    "    device = g.device\n",
    "    num_nodes_per_graph = g.batch_num_nodes()\n",
    "\n",
    "    batch_indxs = torch.cat([\n",
    "        torch.full((num_nodes,), i, dtype=torch.long, device=device)\n",
    "        for i, num_nodes in enumerate(num_nodes_per_graph)\n",
    "    ])\n",
    "    \n",
    "    return batch_indxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([357], device='cuda:0')\n",
      "Graph(num_nodes=357, num_edges=1071,\n",
      "      ndata_schemes={'x_0': Scheme(shape=(3,), dtype=torch.float32), 'h_0': Scheme(shape=(4,), dtype=torch.float32)}\n",
      "      edata_schemes={'a': Scheme(shape=(1,), dtype=torch.float32)})\n",
      "Updated Features Shape: torch.Size([1, 176])\n"
     ]
    }
   ],
   "source": [
    "#setup\n",
    "\n",
    "pocket_to_graph = GraphPocket()\n",
    "\n",
    "g = pocket_to_graph(pocket_path='../../dataset_graph/data/11asA/11asA_pocket.pdb')\n",
    "g = g.to(device)\n",
    "\n",
    "for ntype in g.ntypes:\n",
    "    print(g.batch_num_nodes(ntype))\n",
    "\n",
    "print(g)\n",
    "\n",
    "model = ReceptorEncoderGVP(\n",
    "    in_scalar_size=4,    #Matching the node_features dimension\n",
    "    out_scalar_size=128,  #Desired output scalar size\n",
    "    vector_size=16,       #Desired vector size\n",
    "    n_convs=3,            #Number of convolution layers\n",
    "    dropout=0.1           #Dropout rate\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "batch = torch.tensor([0]).to(device)\n",
    "\n",
    "updated_g = model(g, batch)\n",
    "\n",
    "print(\"Updated Features Shape:\", updated_g.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10962247848510742\n"
     ]
    }
   ],
   "source": [
    "#dataloader\n",
    "import time\n",
    "\n",
    "start= time.time()\n",
    "\n",
    "pos_path, neg_path = '../../dataset_graph/TOUGH-M1/TOUGH-M1_positive.list', '../../dataset_graph/TOUGH-M1/TOUGH-M1_negative.list'\n",
    "pocket_path = '../../dataset_graph/data'\n",
    "seq_file = '../cluster_map.pkl'\n",
    "\n",
    "# train_dataset, test_dataset = create_dataset(pos_path, neg_path, pocket_path, seq_file, fold_nr=0, type='seq')\n",
    "\n",
    "pocket_dir = '../../dataset_graph/data'\n",
    "\n",
    "with open(os.path.join(pocket_dir, 'train_dataset.pkl'), 'rb') as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "with open(os.path.join(pocket_dir, 'test_dataset.pkl'), 'rb') as f:\n",
    "    test_dataset = pickle.load(f)\n",
    "\n",
    "train_dataloader = get_dataloader(train_dataset, batch_size=64, num_workers=4)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print((end-start)/60.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 0/11014 [00:00<?, ?it/s, Loss=0.236, neg_dist=tensor(0.5178, device='cuda:0')]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Memory': 35.31298828125, 'Max Mem': 1061.5341796875}\n",
      "0.23614344000816345\n",
      "0.4319275079234954\n",
      "0.5178184960827683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "\n",
    "epochs = 1\n",
    "warmup_epochs = 5\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)\n",
    "epoch_losses = []\n",
    "s = 1024*1024\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    a,b,c = [],[],[]\n",
    "    \n",
    "    progress_bar = tqdm(enumerate(train_dataloader), total=len(train_dataloader), desc=f'Epoch {epoch+1}/{epochs}')\n",
    "    \n",
    "    for batch_idx, ((graph1, graph2), label) in progress_bar:\n",
    "        torch.cuda.reset_peak_memory_stats(device)\n",
    "        graph1, graph2, label = graph1.to(device), graph2.to(device), label.to(device)\n",
    "\n",
    "        # print(\"After loading Graph: \", {'Memory': torch.cuda.memory_allocated()/s, 'Max Mem': torch.cuda.max_memory_allocated()/s})\n",
    "\n",
    "        batch_indx1 = get_batch_idx(graph1).to(device)\n",
    "        batch_indx2 = get_batch_idx(graph2).to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # print(\"After loading index: \", {'Memory': torch.cuda.memory_allocated()/s, 'Max Mem': torch.cuda.max_memory_allocated()/s})\n",
    "\n",
    "        output1 = model(graph1, batch_indx1)\n",
    "        output2 = model(graph2, batch_indx2)\n",
    "\n",
    "        # print(\"After forward pass: \", {'Memory': torch.cuda.memory_allocated()/s, 'Max Mem': torch.cuda.max_memory_allocated()/s})\n",
    "\n",
    "        # print(output1.shape)\n",
    "        # print(output2.shape)\n",
    "        \n",
    "        loss, pos_dist, neg_dist = con_loss(output1, output2, label)\n",
    "\n",
    "        a.append(loss.item())\n",
    "        b.extend(pos_dist.cpu().numpy().tolist())\n",
    "        c.extend(neg_dist.cpu().numpy().tolist())\n",
    "\n",
    "        # print(\"Before Opt Append: \", {'Memory': torch.cuda.memory_allocated()/s, 'Max Mem': torch.cuda.max_memory_allocated()/s})\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        # print(\"After Opt Append: \", {'Memory': torch.cuda.memory_allocated()/s, 'Max Mem': torch.cuda.max_memory_allocated()/s})        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # print({'Memory': torch.cuda.memory_allocated(), 'Max Mem': torch.cuda.max_memory_allocated()})\n",
    "        \n",
    "        progress_bar.set_postfix({'Loss': running_loss/(batch_idx+1), 'neg_dist': torch.mean(neg_dist)})\n",
    "        epoch_losses.append(running_loss/(batch_idx+1))\n",
    "\n",
    "        if batch_idx%5==0:\n",
    "            print({'Memory': torch.cuda.memory_allocated()/s, 'Max Mem': torch.cuda.max_memory_allocated()/s})\n",
    "            break\n",
    "\n",
    "    print(np.mean(a))\n",
    "    print(np.mean(b))\n",
    "    print(np.mean(c))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(epoch_losses[::500], marker='o')  # 'o' adds markers to each data point\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
