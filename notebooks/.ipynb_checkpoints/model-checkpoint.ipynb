{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Apr  2 23:20:00 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.29.06              Driver Version: 545.29.06    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA RTX A4500               Off | 00000000:1A:00.0 Off |                  Off |\n",
      "| 30%   36C    P8              13W / 200W |      2MiB / 20470MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA RTX A4500               Off | 00000000:3D:00.0 Off |                  Off |\n",
      "| 30%   31C    P8              16W / 200W |      2MiB / 20470MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Wed_Nov_22_10:17:15_PST_2023\n",
      "Cuda compilation tools, release 12.3, V12.3.107\n",
      "Build cuda_12.3.r12.3/compiler.33567101_0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "!nvidia-smi\n",
    "!nvcc --version\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch-scatter in /net/galaxy/home/koes/vratins/miniforge3/envs/graph/lib/python3.10/site-packages (2.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import dgl.function as fn\n",
    "import torch\n",
    "from torch import nn, einsum\n",
    "import torch.nn as nn\n",
    "from torch_scatter import scatter_mean\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from typing import List, Tuple, Union, Dict\n",
    "\n",
    "import sys\n",
    "sys.path.append('/net/galaxy/home/koes/vratins/graphpocket/gnn')\n",
    "\n",
    "from dataloader import get_dataloader, create_dataset\n",
    "from graphpocket import GraphPocket\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prody\n",
    "\n",
    "prody.confProDy(verbosity='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gvp\n",
    "\n",
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "def _norm_no_nan(x, axis=-1, keepdims=False, eps=1e-8, sqrt=True):\n",
    "    '''\n",
    "    L2 norm of tensor clamped above a minimum value `eps`.\n",
    "    \n",
    "    :param sqrt: if `False`, returns the square of the L2 norm\n",
    "    '''\n",
    "    out = torch.clamp(torch.sum(torch.square(x), axis, keepdims), min=eps)\n",
    "    return torch.sqrt(out) if sqrt else out\n",
    "\n",
    "def _rbf(D, D_min=0., D_max=20., D_count=16):\n",
    "    '''\n",
    "    From https://github.com/jingraham/neurips19-graph-protein-design\n",
    "    \n",
    "    Returns an RBF embedding of `torch.Tensor` `D` along a new axis=-1.\n",
    "    That is, if `D` has shape [...dims], then the returned tensor will have\n",
    "    shape [...dims, D_count].\n",
    "    '''\n",
    "    device = D.device\n",
    "    D_mu = torch.linspace(D_min, D_max, D_count, device=device)\n",
    "    D_mu = D_mu.view([1, -1])\n",
    "    D_sigma = (D_max - D_min) / D_count\n",
    "    D_expand = torch.unsqueeze(D, -1)\n",
    "\n",
    "    RBF = torch.exp(-((D_expand - D_mu) / D_sigma) ** 2)\n",
    "    return RBF\n",
    "\n",
    "class GVP(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim_vectors_in,\n",
    "        dim_vectors_out,\n",
    "        dim_feats_in,\n",
    "        dim_feats_out,\n",
    "        hidden_vectors = None,\n",
    "        feats_activation = nn.SiLU(),\n",
    "        vectors_activation = nn.Sigmoid(),\n",
    "        vector_gating = True,\n",
    "        xavier_init = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dim_vectors_in = dim_vectors_in\n",
    "        self.dim_feats_in = dim_feats_in\n",
    "\n",
    "        self.dim_vectors_out = dim_vectors_out\n",
    "        dim_h = max(dim_vectors_in, dim_vectors_out) if hidden_vectors is None else hidden_vectors\n",
    "\n",
    "        # create Wh and Wu matricies\n",
    "        wh_k = 1/math.sqrt(dim_vectors_in)\n",
    "        wu_k = 1/math.sqrt(dim_h)\n",
    "        self.Wh = torch.zeros(dim_vectors_in, dim_h, dtype=torch.float32).uniform_(-wh_k, wh_k)\n",
    "        self.Wu = torch.zeros(dim_h, dim_vectors_out, dtype=torch.float32).uniform_(-wu_k, wu_k)\n",
    "        self.Wh = nn.Parameter(self.Wh)\n",
    "        self.Wu = nn.Parameter(self.Wu)\n",
    "\n",
    "        self.vectors_activation = vectors_activation\n",
    "\n",
    "        self.to_feats_out = nn.Sequential(\n",
    "            nn.Linear(dim_h + dim_feats_in, dim_feats_out),\n",
    "            feats_activation\n",
    "        )\n",
    "\n",
    "        # branching logic to use old GVP, or GVP with vector gating\n",
    "        if vector_gating:\n",
    "            self.scalar_to_vector_gates = nn.Linear(dim_feats_out, dim_vectors_out)\n",
    "            if xavier_init:\n",
    "                nn.init.xavier_uniform_(self.scalar_to_vector_gates.weight, gain=1)\n",
    "                nn.init.constant_(self.scalar_to_vector_gates.bias, 0)\n",
    "        else:\n",
    "            self.scalar_to_vector_gates = None\n",
    "\n",
    "    def forward(self, data):\n",
    "        feats, vectors = data\n",
    "        b, n, _, v, c  = *feats.shape, *vectors.shape\n",
    "\n",
    "        assert c == 3 and v == self.dim_vectors_in, 'vectors have wrong dimensions'\n",
    "        assert n == self.dim_feats_in, 'scalar features have wrong dimensions'\n",
    "\n",
    "        Vh = einsum('b v c, v h -> b h c', vectors, self.Wh)\n",
    "        Vu = einsum('b h c, h u -> b u c', Vh, self.Wu)\n",
    "\n",
    "        sh = _norm_no_nan(Vh)\n",
    "\n",
    "        s = torch.cat((feats, sh), dim = 1)\n",
    "\n",
    "        feats_out = self.to_feats_out(s)\n",
    "\n",
    "        if exists(self.scalar_to_vector_gates):\n",
    "            gating = self.scalar_to_vector_gates(feats_out)\n",
    "            gating = gating.unsqueeze(dim = -1)\n",
    "        else:\n",
    "            gating = _norm_no_nan(Vu)\n",
    "\n",
    "        vectors_out = self.vectors_activation(gating) * Vu\n",
    "\n",
    "        # if torch.isnan(feats_out).any() or torch.isnan(vectors_out).any():\n",
    "        #     raise ValueError(\"NaNs in GVP forward pass\")\n",
    "\n",
    "        return (feats_out, vectors_out)\n",
    "    \n",
    "class _VDropout(nn.Module):\n",
    "    '''\n",
    "    Vector channel dropout where the elements of each\n",
    "    vector channel are dropped together.\n",
    "    '''\n",
    "    def __init__(self, drop_rate):\n",
    "        super(_VDropout, self).__init__()\n",
    "        self.drop_rate = drop_rate\n",
    "        self.dummy_param = nn.Parameter(torch.empty(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        :param x: `torch.Tensor` corresponding to vector channels\n",
    "        '''\n",
    "        device = self.dummy_param.device\n",
    "        if not self.training:\n",
    "            return x\n",
    "        mask = torch.bernoulli(\n",
    "            (1 - self.drop_rate) * torch.ones(x.shape[:-1], device=device)\n",
    "        ).unsqueeze(-1)\n",
    "        x = mask * x / (1 - self.drop_rate)\n",
    "        return x\n",
    "    \n",
    "class GVPDropout(nn.Module):\n",
    "    \"\"\" Separate dropout for scalars and vectors. \"\"\"\n",
    "    def __init__(self, rate):\n",
    "        super().__init__()\n",
    "        self.vector_dropout = _VDropout(rate)\n",
    "        self.feat_dropout = nn.Dropout(rate)\n",
    "\n",
    "    def forward(self, feats, vectors):\n",
    "        return self.feat_dropout(feats), self.vector_dropout(vectors)\n",
    "\n",
    "\n",
    "class GVPLayerNorm(nn.Module):\n",
    "    \"\"\" Normal layer norm for scalars, nontrainable norm for vectors. \"\"\"\n",
    "    def __init__(self, feats_h_size, eps = 1e-5):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.feat_norm = nn.LayerNorm(feats_h_size)\n",
    "\n",
    "    def forward(self, feats, vectors):\n",
    "\n",
    "        normed_feats = self.feat_norm(feats)\n",
    "\n",
    "        vn = _norm_no_nan(vectors, axis=-1, keepdims=True, sqrt=False)\n",
    "        vn = torch.sqrt(torch.mean(vn, dim=-2, keepdim=True) + self.eps ) + self.eps\n",
    "        normed_vectors = vectors / vn\n",
    "        return normed_feats, normed_vectors\n",
    "    \n",
    "#convolution\n",
    "class GVPEdgeConv(nn.Module):\n",
    "\n",
    "    def __init__(self, scalar_size: int = 128, vector_size: int = 16,\n",
    "                  scalar_activation=nn.SiLU, vector_activation=nn.Sigmoid,\n",
    "                  n_message_gvps: int = 1, n_update_gvps: int = 1,\n",
    "                  rbf_dmax: float = 3.5, rbf_dim: int = 16,\n",
    "                  edge_feat_size: int = 0, message_norm: Union[float, str] = 4, dropout: float = 0.0,):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.scalar_size = scalar_size\n",
    "        self.vector_size = vector_size\n",
    "        self.scalar_activation = scalar_activation\n",
    "        self.vector_activation = vector_activation\n",
    "        self.n_message_gvps = n_message_gvps\n",
    "        self.n_update_gvps = n_update_gvps\n",
    "        self.edge_feat_size = edge_feat_size\n",
    "        self.rbf_dmax = rbf_dmax\n",
    "        self.rbf_dim = rbf_dim\n",
    "        self.dropout_rate = dropout\n",
    "        self.message_norm = message_norm\n",
    "\n",
    "        # create message passing function\n",
    "        message_gvps = []\n",
    "        for i in range(n_message_gvps):\n",
    "\n",
    "            dim_vectors_in = vector_size\n",
    "            dim_feats_in = scalar_size\n",
    "\n",
    "            # on the first layer, there is an extra edge vector for the displacement vector between the two node positions\n",
    "            if i == 0:\n",
    "                dim_vectors_in += 1\n",
    "                dim_feats_in += rbf_dim\n",
    "\n",
    "            message_gvps.append(\n",
    "                GVP(dim_vectors_in=dim_vectors_in, \n",
    "                    dim_vectors_out=vector_size, \n",
    "                    dim_feats_in=dim_feats_in, \n",
    "                    dim_feats_out=scalar_size, \n",
    "                    feats_activation=scalar_activation(), \n",
    "                    vectors_activation=vector_activation(), \n",
    "                    vector_gating=True)\n",
    "            )\n",
    "        self.edge_message = nn.Sequential(*message_gvps)\n",
    "\n",
    "        # create update function\n",
    "        update_gvps = []\n",
    "        for i in range(n_update_gvps):\n",
    "            update_gvps.append(\n",
    "                GVP(dim_vectors_in=vector_size, \n",
    "                    dim_vectors_out=vector_size, \n",
    "                    dim_feats_in=scalar_size, \n",
    "                    dim_feats_out=scalar_size, \n",
    "                    feats_activation=scalar_activation(), \n",
    "                    vectors_activation=vector_activation(), \n",
    "                    vector_gating=True)\n",
    "            )\n",
    "        self.node_update = nn.Sequential(*update_gvps)\n",
    "\n",
    "        \n",
    "        self.dropout = GVPDropout(self.dropout_rate)\n",
    "        self.message_layer_norm = GVPLayerNorm(self.scalar_size)\n",
    "        self.update_layer_norm = GVPLayerNorm(self.scalar_size)\n",
    "\n",
    "        if self.message_norm == 'mean':\n",
    "            self.agg_func = fn.mean\n",
    "        else:\n",
    "            self.agg_func = fn.sum\n",
    "\n",
    "    def forward(self, g: dgl.DGLHeteroGraph, \n",
    "                rec_feats: Tuple[torch.Tensor, torch.Tensor, torch.Tensor], \n",
    "                edge_feats: torch.Tensor = None, \n",
    "                z: Union[float, torch.Tensor] = 1):\n",
    "        # vec_feat has shape (n_nodes, n_vectors, 3)\n",
    "\n",
    "        with g.local_scope():\n",
    "\n",
    "            scalar_feat, coord_feat, vec_feat = rec_feats\n",
    "            g.ndata[\"h\"] = scalar_feat\n",
    "            g.ndata[\"x\"] = coord_feat\n",
    "            g.ndata[\"v\"] = vec_feat\n",
    "            \n",
    "            # edge feature\n",
    "            if self.edge_feat_size > 0:\n",
    "                assert edge_feats is not None, \"Edge features must be provided.\"\n",
    "                g.edata[\"a\"] = edge_feats\n",
    "\n",
    "            # get vectors between node positions\n",
    "            g.apply_edges(fn.u_sub_v(\"x\", \"x\", \"x_diff\"))\n",
    "\n",
    "            # normalize x_diff and compute rbf embedding of edge distance\n",
    "            # dij = torch.norm(g.edges[self.edge_type].data['x_diff'], dim=-1, keepdim=True)\n",
    "            dij = _norm_no_nan(g.edata['x_diff'], keepdims=True) + 1e-8\n",
    "            g.edata['x_diff'] = g.edata['x_diff'] / dij\n",
    "            g.edata['d'] = _rbf(dij.squeeze(1), D_max=self.rbf_dmax, D_count=self.rbf_dim)\n",
    "\n",
    "            # compute messages on every edge\n",
    "            g.apply_edges(self.message)\n",
    "\n",
    "            # aggregate messages from every edge\n",
    "            g.update_all(fn.copy_e(\"scalar_msg\", \"m\"), self.agg_func(\"m\", \"scalar_msg\"))\n",
    "            g.update_all(fn.copy_e(\"vec_msg\", \"m\"), self.agg_func(\"m\", \"vec_msg\"))\n",
    "\n",
    "\n",
    "            # get aggregated scalar and vector messages\n",
    "            scalar_msg = g.ndata[\"scalar_msg\"] / z\n",
    "            if isinstance(z, torch.Tensor):\n",
    "                z = z.unsqueeze(-1)\n",
    "            vec_msg = g.ndata[\"vec_msg\"] / z\n",
    "\n",
    "            # dropout scalar and vector messages\n",
    "            scalar_msg, vec_msg = self.dropout(scalar_msg, vec_msg)\n",
    "\n",
    "            # update scalar and vector features, apply layernorm\n",
    "            scalar_feat = g.ndata['h'] + scalar_msg\n",
    "            vec_feat = g.ndata['v'] + vec_msg\n",
    "            scalar_feat, vec_feat = self.message_layer_norm(scalar_feat, vec_feat)\n",
    "\n",
    "            # apply node update function, apply dropout to residuals, apply layernorm\n",
    "            scalar_residual, vec_residual = self.node_update((scalar_feat, vec_feat))\n",
    "            scalar_residual, vec_residual = self.dropout(scalar_residual, vec_residual)\n",
    "            scalar_feat = scalar_feat + scalar_residual\n",
    "            vec_feat = vec_feat + vec_residual\n",
    "            scalar_feat, vec_feat = self.update_layer_norm(scalar_feat, vec_feat)\n",
    "\n",
    "        return scalar_feat, vec_feat\n",
    "\n",
    "    def message(self, edges):\n",
    "\n",
    "        vec_feats = torch.cat([edges.data[\"x_diff\"].unsqueeze(1), edges.src[\"v\"]], dim=1)\n",
    "\n",
    "        # create scalar features\n",
    "        scalar_feats = [ edges.src['h'], edges.data['d'] ]\n",
    "\n",
    "        # if self.edge_feat_size > 0:\n",
    "        #     scalar_feats.append(edges.data['a'])\n",
    "\n",
    "        scalar_feats = torch.cat(scalar_feats, dim=1)\n",
    "\n",
    "        scalar_message, vector_message = self.edge_message((scalar_feats, vec_feats))\n",
    "\n",
    "        return {\"scalar_msg\": scalar_message, \"vec_msg\": vector_message}\n",
    "\n",
    "    \n",
    "class ReceptorEncoderGVP(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 in_scalar_size: int, \n",
    "                 out_scalar_size: int = 128, \n",
    "                 n_message_gvps: int = 1,\n",
    "                 n_update_gvps: int = 1,\n",
    "                 vector_size: int = 16,\n",
    "                 n_convs: int = 3, \n",
    "                 message_norm: Union[float, str] = 10, \n",
    "                 dropout: float = 0.0,\n",
    "                 rbf_dmax: float = 3.5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_convs = n_convs\n",
    "        self.in_scalar_size = in_scalar_size\n",
    "        self.out_scalar_size = out_scalar_size\n",
    "        self.vector_size = vector_size\n",
    "        self.dropout_rate = dropout\n",
    "        self.message_norm = message_norm\n",
    "        self.rbf_dmax = rbf_dmax\n",
    "\n",
    "        # check the message norm argument\n",
    "        if isinstance(message_norm, str) and message_norm != 'mean':\n",
    "            raise ValueError(f'message norm must be either a float, int, or \"mean\". Got {message_norm}')\n",
    "        elif isinstance(message_norm, float) or isinstance(message_norm, int):\n",
    "            pass\n",
    "        elif not isinstance(message_norm, (str, float, int)):\n",
    "            raise ValueError(f'message norm must be either a float, int, or \"mean\". Got {message_norm}')\n",
    "\n",
    "        # create functions to embed scalar features to the desired size\n",
    "        self.scalar_embed = nn.Sequential(\n",
    "            nn.Linear(in_scalar_size, out_scalar_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(out_scalar_size, out_scalar_size),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "        self.scalar_norm = nn.LayerNorm(out_scalar_size)\n",
    "\n",
    "        edge_feat_size = 1\n",
    "\n",
    "        # create rec-rec convolutional layers\n",
    "        self.rec_conv_layers = nn.ModuleList()\n",
    "        for _ in range(n_convs):\n",
    "            self.rec_conv_layers.append(GVPEdgeConv(\n",
    "                scalar_size=out_scalar_size,\n",
    "                vector_size=vector_size,\n",
    "                n_message_gvps=n_message_gvps,\n",
    "                n_update_gvps=n_update_gvps,\n",
    "                edge_feat_size=edge_feat_size,\n",
    "                dropout=dropout,\n",
    "                message_norm=message_norm,\n",
    "                rbf_dmax=rbf_dmax\n",
    "            ))\n",
    "\n",
    "    def forward(self, g: dgl.DGLHeteroGraph, batch_idx: torch.Tensor):\n",
    "\n",
    "        device = g.device\n",
    "        batch_size = g.batch_size\n",
    "\n",
    "        # get scalar features\n",
    "        rec_scalar_feat = g.ndata[\"h_0\"]\n",
    "\n",
    "        # embed scalar features\n",
    "        rec_scalar_feat = self.scalar_embed(rec_scalar_feat)\n",
    "        rec_scalar_feat = self.scalar_norm(rec_scalar_feat)\n",
    "\n",
    "        # initialize receptor vector features\n",
    "        rec_vec_feat = torch.zeros((g.num_nodes(), self.vector_size, 3), device=device)\n",
    "\n",
    "        # get edge features\n",
    "        edge_feat = g.edata['a']\n",
    "\n",
    "        # get coordinate features\n",
    "        rec_coord_feat = g.ndata['x_0']\n",
    "\n",
    "        # compute the normalization factor for the messages if necessary\n",
    "        if self.message_norm == 'mean':\n",
    "            # set z to 1. the receptor convolutional layer will use mean aggregation instead of sum\n",
    "            z = 1\n",
    "        elif self.message_norm == 0:\n",
    "            # if messsage_norm is 0, we normalize by the average in-degree of the graph\n",
    "            z = g.batch_num_edges() / g.batch_num_nodes()\n",
    "            z = z[batch_idx].view(-1, 1)\n",
    "        else:\n",
    "            z = self.message_norm\n",
    "\n",
    "        # apply receptor-receptor convolutions\n",
    "        for i in range(self.n_convs):\n",
    "            rec_feats = (rec_scalar_feat, rec_coord_feat, rec_vec_feat)\n",
    "            rec_scalar_feat, rec_vec_feat = self.rec_conv_layers[i](g, rec_feats=rec_feats, edge_feats=edge_feat, z=z)\n",
    "\n",
    "        vector_features_flattened = rec_vec_feat.view(rec_vec_feat.size(0), -1)  # Reshapes to [num_nodes, num_vectors * vector_dim]\n",
    "\n",
    "        #concatenate the scalar and vector features\n",
    "        flattened_features = torch.cat([rec_scalar_feat, vector_features_flattened], dim=1)\n",
    "        #average the features across the graphs in batch, return a tensor of shape [batch_size, feature length]\n",
    "        graph_features = scatter_mean(flattened_features, batch_idx, dim=0)\n",
    "        \n",
    "        return graph_features\n",
    "\n",
    "\n",
    "def con_loss(output1, output2, labels, margin=1.0):\n",
    "\n",
    "    dists = F.pairwise_distance(output1, output2).view(-1)\n",
    "    \n",
    "    pos_loss = dists.pow(2)\n",
    "    neg_loss = torch.clamp(margin - dists, min=0).pow(2)\n",
    "\n",
    "    loss_contrastive = torch.sum(pos_loss * labels + neg_loss * (1 - labels)) / labels.numel()\n",
    "\n",
    "    return loss_contrastive, dists[labels > 0.5].detach(), dists[labels < 0.5].detach()\n",
    "\n",
    "def get_batch_idx(g: dgl.DGLHeteroGraph) -> torch.Tensor:\n",
    "        \n",
    "    batch_size = g.batch_size\n",
    "    device = g.device\n",
    "    num_nodes_per_graph = g.batch_num_nodes()\n",
    "\n",
    "    batch_indxs = torch.cat([\n",
    "        torch.full((num_nodes,), i, dtype=torch.long, device=device)\n",
    "        for i, num_nodes in enumerate(num_nodes_per_graph)\n",
    "    ])\n",
    "    \n",
    "    return batch_indxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([357], device='cuda:0')\n",
      "Graph(num_nodes=357, num_edges=1071,\n",
      "      ndata_schemes={'x_0': Scheme(shape=(3,), dtype=torch.float32), 'h_0': Scheme(shape=(4,), dtype=torch.float32)}\n",
      "      edata_schemes={'a': Scheme(shape=(1,), dtype=torch.float32)})\n",
      "Updated Features Shape: torch.Size([1, 176])\n"
     ]
    }
   ],
   "source": [
    "#setup\n",
    "\n",
    "pocket_to_graph = GraphPocket()\n",
    "\n",
    "g = pocket_to_graph(pocket_path='../../dataset_graph/data/11asA/11asA_pocket.pdb')\n",
    "g = g.to(device)\n",
    "\n",
    "for ntype in g.ntypes:\n",
    "    print(g.batch_num_nodes(ntype))\n",
    "\n",
    "print(g)\n",
    "\n",
    "model = ReceptorEncoderGVP(\n",
    "    in_scalar_size=4,    #Matching the node_features dimension\n",
    "    out_scalar_size=128,  #Desired output scalar size\n",
    "    vector_size=16,       #Desired vector size\n",
    "    n_convs=3,            #Number of convolution layers\n",
    "    dropout=0.1           #Dropout rate\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "batch = torch.tensor([0]).to(device)\n",
    "\n",
    "updated_g = model(g, batch)\n",
    "\n",
    "print(\"Updated Features Shape:\", updated_g.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting dataset based on Sequence Clusters..\n",
      "Split complete, reading pockets..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering train pos_list: 100%|██████████| 505116/505116 [00:43<00:00, 11530.50it/s]\n",
      "Filtering train neg_list: 100%|██████████| 556810/556810 [00:47<00:00, 11802.37it/s]\n",
      "Reading train Pockets: 5955it [00:56, 104.59it/s]\n",
      "Creating train Positive Pocket Pairs: 100%|██████████| 326259/326259 [00:00<00:00, 1381601.62it/s]\n",
      "Creating train Negative Pocket Pairs: 100%|██████████| 378576/378576 [00:01<00:00, 337218.66it/s]\n",
      "Filtering test pos_list: 100%|██████████| 505116/505116 [00:11<00:00, 44830.31it/s]\n",
      "Filtering test neg_list: 100%|██████████| 556810/556810 [00:12<00:00, 44735.01it/s]\n",
      "Reading test Pockets: 1543it [00:14, 104.55it/s]\n",
      "Creating test Positive Pocket Pairs: 100%|██████████| 21254/21254 [00:00<00:00, 828538.18it/s]\n",
      "Creating test Negative Pocket Pairs: 100%|██████████| 16099/16099 [00:00<00:00, 848783.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1706675330797833\n"
     ]
    }
   ],
   "source": [
    "#dataloader\n",
    "import time\n",
    "\n",
    "start= time.time()\n",
    "\n",
    "pos_path, neg_path = '../../dataset_graph/TOUGH-M1/TOUGH-M1_positive.list', '../../dataset_graph/TOUGH-M1/TOUGH-M1_negative.list'\n",
    "pocket_path = '../../dataset_graph/data'\n",
    "seq_file = '../cluster_map.pkl'\n",
    "\n",
    "train_dataset, test_dataset = create_dataset(pos_path, neg_path, pocket_path, seq_file, fold_nr=0, type='seq')\n",
    "train_dataloader = get_dataloader(train_dataset, batch_size=64, num_workers=4)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print((end-start)/60.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 11014/11014 [17:51<00:00, 10.28it/s, Loss=0.167, neg_dist=tensor(0.7308, device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "\n",
    "epochs = 1\n",
    "warmup_epochs = 5\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)\n",
    "epoch_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    progress_bar = tqdm(enumerate(train_dataloader), total=len(train_dataloader), desc=f'Epoch {epoch+1}/{epochs}')\n",
    "    \n",
    "    for batch_idx, ((graph1, graph2), label) in progress_bar:\n",
    "        graph1, graph2, label = graph1.to(device), graph2.to(device), label.to(device)\n",
    "\n",
    "        batch_indx1 = get_batch_idx(graph1).to(device)\n",
    "        batch_indx2 = get_batch_idx(graph2).to(device)\n",
    "        \n",
    "        output1 = model(graph1, batch_indx1)\n",
    "        output2 = model(graph2, batch_indx2)\n",
    "\n",
    "        # print(output1.shape)\n",
    "        # print(output2.shape)\n",
    "        \n",
    "        loss, pos_dist, neg_dist = con_loss(output1, output2, label)\n",
    "\n",
    "        # print(\"loss: \", loss)\n",
    "        # print(\"pos_dist: \", pos_dist, \"len pos: \", len(pos_dist))\n",
    "        # print(\"neg_dist: \", neg_dist, \"len neg: \", len(neg_dist))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print(loss.item())\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        progress_bar.set_postfix({'Loss': running_loss/(batch_idx+1), 'neg_dist': torch.mean(neg_dist)})\n",
    "        epoch_losses.append(running_loss/(batch_idx+1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(epoch_losses[::500], marker='o')  # 'o' adds markers to each data point\n",
    "plt.title('Line Plot of List Items')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
